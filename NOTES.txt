DEPENDENCIES

 - C/C++
 - GNU Make


GIT BRANCHES

  - master: main development
  - BitSet-test
  - double-move: experiment with allowing a two moves in the final turn
    (Louis' rule; see CodeCup forum for details)
  - no-reduce: player from before the rule change (MUST_REDUCE=0)
    (obsolete; should be deleted)
  - proof-number-search-wip: partial implementation of proof-number-search
    (obsolete; should be deleted)


BUILDING

To build all binaries, simply run make:

% make -j4

Output files are in output/

To build just debug/release binaries:

% make debug  # or release

To create the combined player source file at output/player-combined.cc:

% make combined

To only build e.g. a release build of the solver:

% make -f Makefile.release solver


RULE CHANGE

After the start of the CodeCup, the rules were changed so that each move must
reduce the number of solutions (in addition to keeping at least 1 solution).
Without that change, the game was always winnable by Player 1. See discussion
here: https://forum.codecup.nl/read.php?31,2248

I've deleted the notes related to the strategy in the old version of the game.


STRATEGY

Let's call the digits that were already placed in the grid the *givens*, or more
accurately: the givens are nonconflicting (cell, digit) pairs.

For a set of givens, we can (sometimes) enumerate all possible solutions in the
grid. Assume we have a full set of solutions. Let's call the candidates of a
cell the set of digits that occurs in that cell across all solutions. We are
only allowed to play in a cell if it has at least two candidates (otherwise, we
would not reduce the number of solutions).


TRANSPOSITION TABLE

The game tree is not a tree, but a directed acyclic graph (DAG), which means a
naive search algorithm would evaluate the same position many times. To avoid
duplicate work, I have implemented a transposition table to cache intermediate
results (see src/memo.h).

The result of a state is determined by the set of solutions. The memo is indexed
with a 64-bit key that is calculated by hashing the solution set.

The solutions hash is calculated by assigned a hash code to each solution
(a 64-bit FNV-1a hash of the digits 1-9), and calculating the hash of a solution
set as the XOR of the solution hashes. This has the advantage that the hash is
not dependend on the order of the solutions. Hashes are precomputed and stored
along the solutions to avoid having to re-hash the same solution multiple times.

As an alternative, it's also possible to maintain a Zobrist hash of the current
position, by hashing all fixed and inferred digits, which determines the
solution set! Note that including inferred digits in the hash is required
because there are many different sets of digits that could lead to the same set
of possible solutions, but the union of fixed and inferred digits is unique for
each solution set (pretty much by definition).

In practice this is slower, however, probably because in deep nodes of the
search tree the number of solutions is fairly low, but the number of inferred
digits is high, so hashing all those digits is more expensive than combining the
solution hashes. For an implementation of the Zobrist hashing idea, see:
backups/hash_determined_digits_instead_of_solutions.diff


STATISTICS

I did some profiling of analysis.cc and found the following stats on the number
of solutions (solutions.size()) that are passed to IsWinning() for this state:

% time output/release/solver --analyze-batch_size=1e8 \
8..1......36..7..9.1.43.......3...48.......5.3........5.....8.3....82...2........

(..)

              samples  avg.    0%   10%   20%   30%   40%   50%   60%   70%   80%   90%   91%   92%   93%   94%   95%   96%   97%   98%   99%  100%
win. sols     1115342  15.2     2     3     5     6     8    11    13    17    22    32    33    35    37    40    43    47    52    60    75  2530
rem. sols      383400  25.4     4     6     8    10    12    16    20    25    34    51    54    57    61    66    71    79    90   108   151  4380
rem. posits    383400  26.2     8    14    18    21    24    27    29    32    34    38    38    38    39    39    40    40    41    42    43    54
rem. moves     383400  64.3    16    30    38    46    54    61    69    78    89   103   105   107   109   112   115   118   122   127   136   224

Outcome: WIN2
1 optimal turns: Ag6

Counters{
        max_depth=18,
        recursive_calls=9920857,
        total_solutions=76708443,
        immediately_won=1115342,  # 1115342 / 1498742 = ~74%
        memo_accessed=9920856,
        memo_returned=8422114,  # ~85%
        memo_collisions=0,
}

real    0m3.844s
user    0m3.780s
sys     0m0.043s

This shows a few interesting things:

    - ~85% of calls can be served from the memo.
    - of the remaining states, ~75% have an immmediately winning move.
    - the number of solutions is low (mean 25.4, median of 16),
      so are the number of choice positions and number of moves.

This shows solution sets are skewed towards relatively small sizes, and the
sorting algorithm should be optimized for those cases.


SOLUTION ENUMERATION TIMING

Using 100 cases with solution counts below 1,000,000 (average 410,817)
from data/random-play-until-1m-cases.txt, I timed how long it took to count the
number of solutions:

   JCZSolve10:     10.76 s
   tdoku:          12.10 s  (SAT solver, SIMD optimized)
   My solver:      18.94 s  (recursive backtracking)
   fss2:           22.66 s
   alphadoku dlxc: 31.51 s  (DLX, C++)

My solver is a straightforward backtracking solver which always backtracks on
the most constrained cell (i.e. with the fewest candidates remaining). Main
takeways:

  1. My solver is quite competitive for this task: it is only about twice as
     slow as the fastest solver!
  2. EnumerateSolutions() is not noticably slower than CountSolutions().


ANALYSIS TIMING

I collected some timing statistics. If I use the total_solutions counter as
a proxy for amount of work performed, then I can analyze between 12e6 and 30e6
solutions per second on my laptop.

So assuming CodeCup servers are twice as slow and I don't want to spend more
than 20s on analysis, I should set the analysis work limit to 120e6.

NOTE: above analysis is based on data from before the rule change, so it is
not necessarily valid anymore!

Comparison of performance before/after move ordering and without/with solution
reduction rule in effect. Benchmarked with:

% time awk '{ print $3 }' data/random-play-until-2k-cases.txt | head -100 | xargs -IX backups/ordering\=0_must_reduce\=0/release/solver X | stdbuf -oL grep Outcome | stdbuf -oL nl

User time reported:

  - must_reduce=0 ordering=0:   56.668s
  - must_reduce=0 ordering=1:    2.147s (26.39x speedup!)
  - must_reduce=1 ordering=0: 1028.438s
  - must_reduce=1 ordering=1:   12.763s (80.58x speedup!)

Conclusion: move ordering is highly effective, and even more so with the
new rule change.


OPEN QUESTIONS

Can we meaningfully decompose the game?

At first glance, it seems like we can identify independent parts of the grid
and solve them independently.

For example, if we have only the top-left box with the following candidates:

    [123] [123] [123]   4  5  6   7  8  9
    [456] [456] [456]   7  8  9   1  2  3
    [78]  [78]    9     1  2  3   4  5  6

Then the puzzle can be decomposed into 3 parts (the rows of the box) which
are solved independently.

The main problem here is that earlier in the game, when it matters the most,
there typically aren't obvious independent parts.


CAIA NOTES

  - Server sometimes sends empty lines (has this been fixed?)
    https://forum.codecup.nl/read.php?31,2221
  - Best guess as to what the sample players do:
      - player1 plays a random valid move, but never claims a win.
      - player2 plays a random valid move, and also claims a win if the solution
        is unique at the start of its turn ("!") or after its move ("Xx0!")
      - player3 plays a winning move if there is one, otherwise plays randomly.


CODECUP SERVER NOTES

  - 64 bit
  - GCC 11.3.0 (release date: April 21, 2022)
  - referee does NOT send Quit after I send my winning move. So I cannot
    write statistics to stderr before exiting; I have to do it before my last
    move.
  - Speed: initial analysis suggests the Codecup CPU
    (Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz) is half the speed of my laptop
    (Intel(R) Core(TM) i7-7560U CPU @ 2.40GHz), which kind of makes sense since
    my laptop CPU supports bursts up to 3.80 GHz.


RELEASE INSTRUCTIONS

  1. `git status` # Make sure all changes are commited!
  2. `make clean`, `make -j4 all combined`
  3. Use arbiter.py to run a competition with the new and previous players
  4. Check player logs for unexpected warnings/errors.
  5. Submit to CodeCup.
  6. `git tag submission-#-id-#`
  7. Make a backup: `cp -r output/ backups/$(git rev-parse --short HEAD)`


AFTER EACH TEST COMPETITION

   1. Download competition csv, move to:
      competition-results/test-X-competition-Y.csv

   2. Download game details for competition:

      % tools/fetch-competition.py
          tmp/cache/ \
          competition-results/test-X-competition-Y.csv \
          competition-results/test-X-competition-Y-games.csv

   3. Download my playerlogs:

      % tools/fetch-competition-playerlogs.sh test-X-competition-Y 'Maks Verver'

   4. Commit to git

      % git add competition-results/ playerlogs/
      % git commit -m 'Add test competition X data.'

   5. Post to CodeCup forum: https://forum.codecup.nl/read.php?31,2264
